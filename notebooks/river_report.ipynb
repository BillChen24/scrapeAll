{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ffd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5473b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates for the scraping\n",
    "start_date = pd.Timestamp('2015-01-01')\n",
    "end_date = pd.Timestamp.now()\n",
    "output_folder = 'river_report/'\n",
    "output_path = os.path.join(os.getcwd(), output_folder)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9486a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3055/3055 [32:49<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "# Create a dictionary to store the scraped data for each station\n",
    "station_data = {}\n",
    "\n",
    "# loop over each date in the range\n",
    "for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "    # create the URL\n",
    "    url = f'http://113.57.190.228:8001/Web/Report/GetRiverData?date={date.date()}+08%3A00'\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Request failed for {url}: {e}')\n",
    "            if i == 2:\n",
    "                print(f'Failed to get data for {date_str} after {i+1} retries, skipping...')\n",
    "                continue\n",
    "            print(f'Retrying in 5 seconds...')\n",
    "            time.sleep(5)\n",
    "    # make the request\n",
    "    #response = requests.get(url)\n",
    "    # extract the JSON data\n",
    "    data = json.loads(response.text)\n",
    "    # loop over each row in the data\n",
    "    for row in data['rows']:\n",
    "        # get the station name\n",
    "        station_name = row['STNM']\n",
    "        # create a dictionary for the station if it doesn't exist\n",
    "        if station_name not in station_data:\n",
    "            station_data[station_name] = {}\n",
    "        # add the data for the station on this date\n",
    "        station_data[station_name][date.date()] = {'河名': row['RVNM'], \n",
    "                                                   '水位': row['Z'],\n",
    "                                                   '水势': row['WPTN'],\n",
    "                                                   '比昨日+涨-落': row['YZ'],\n",
    "                                                   '流量': row['Q'],\n",
    "                                                   '设防水位': row['FRZ'],\n",
    "                                                   '警戒水位': row['WRZ'],\n",
    "                                                   '保证水位': row['GRZ']\n",
    "                                                  }\n",
    "        \n",
    "        # get the second station name\n",
    "        station_name_1 = row['STNM1']\n",
    "        # create a dictionary for the station if it doesn't exist\n",
    "        if station_name_1 not in station_data:\n",
    "            station_data[station_name_1] = {}\n",
    "        # add the data for the station on this date\n",
    "        station_data[station_name_1][date.date()] = {'河名': row['RVNM1'], \n",
    "                                                   '水位': row['Z1'],\n",
    "                                                   '水势': row['WPTN1'],\n",
    "                                                   '比昨日+涨-落': row['YZ1'],\n",
    "                                                   '流量': row['Q1'],\n",
    "                                                   '设防水位': row['FRZ1'],\n",
    "                                                   '警戒水位': row['WRZ1'],\n",
    "                                                   '保证水位': row['GRZ1']\n",
    "                                                  }\n",
    "\n",
    "# convert the dictionary to a DataFrame\n",
    "df_dict = {}\n",
    "for station, data in station_data.items():\n",
    "    df_dict[station] = pd.DataFrame.from_dict(data, orient='index')\n",
    "    \n",
    "# save each DataFrame to a separate CSV file\n",
    "for station, df in df_dict.items():\n",
    "    outpath = os.path.join(output_path, f'{station}.csv')\n",
    "    df.to_csv(outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5f64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
